{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13i7KQ9t-CV8"
      },
      "source": [
        "# Problem set 2\n",
        "\n",
        "## Team\n",
        "Please write here your names and team number.\n",
        "\n",
        "* Team name:\n",
        "* Team members:\n",
        "\n",
        "## Using Colab with GitHub\n",
        "To utilize GPU support for model training, we highly recommend to open this notebook with Google Colab. Simply, change the domain from 'github.com' to 'githubtocolab.com' and refresh the site to open the notebook in Colab.\n",
        "If you haven't used Colab before with private repositories, make sure to grant Colab access to your private repositories (see screenshot) and after that just try to change the domain again.\n",
        "\n",
        "Finally, you should make sure that you add a GPU to your Colab notebook. You can do so by clicking on `Runtime` →  `Change runtime type` → `Hardware accelerator`  →  `GPU`.\n",
        "\n",
        "## Submission\n",
        "\n",
        "Make sure that you always commit and push the changes you make in Colab back to GitHub. To do so from within a Colab notebook, click `File` → `Save a copy in GitHub`. You will be prompted to add a commit message, and after you click OK, the notebook will be pushed to your repository. Only changes that are visible in your GitHub repository on the main branch will be considered for grading. If you close Colab in your browser without pushing your changes to GitHub or saving them on Google Drive, they will be lost.\n",
        "\n",
        "Make sure that all your work has been pushed to GitHub before the deadline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ffVUKx7P6RD"
      },
      "source": [
        "Check that the GPU  enabled in your colab notebook by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPzhNed7P2i9",
        "outputId": "1a41ea29-01db-4e22-eb0e-0aa8517bc5d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Check is GPU is enabled\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: {}\".format(device))d\n",
        "\n",
        "# Get specific GPU model\n",
        "if str(device) == \"cuda:0\":\n",
        "  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29zJt4eFI25Y"
      },
      "source": [
        "You will be working with the EuroSAT dataset. The dataset contains 8489 pictures of 3 different land coverage types (crop, herbaceous vegetation and river). Running the lines below will download the data and return a random picture from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MgSuuP3Kjx0",
        "outputId": "fb3fdb72-771f-4a38-cab5-aa12c2fb0ed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dataset has 8489 images\n",
            "Picture number 1280 with label: 0\n"
          ]
        },
        {
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCuM4oBxQTTC1SlbQ6CVW4pCM1EGNSKw70bBcaOppcc0HqaBjPJpgO5xSjJNNyPWopLyGEHdIA3p1NCi3sJyS3HseajY01nAqOS4jQfM4H86pJkuSW5IDUin8azX1FR9xS3+9wKqyXs0n8e0ei8Vfsm9zN1orY2ZriOL7zqD6Z5qjNqYB/dqT7t0rMLHNRkmrjCC8zKVaTLUt5LJwXOPQcVX3E803mkzV37GTbe5de7mk4L4HoOKrseetKEOKYVI60k+wN9xQeaM803Bz0pSGHakIU7femn6UYOetJzQA7HHSmnrS80nehASlhTD6mko5pIAPWjPqaKMc0wEakpxzjrSY96AFApCD1p2eOtIfrQB//Z",
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchvision.datasets import EuroSAT\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "data = EuroSAT(root=os.getcwd(), download=True) #downloads the dataset to your current directory\n",
        "print(f\"The dataset has {len(data)} images\")\n",
        "randint = np.random.randint(len(data))\n",
        "\n",
        "pic, tar = data[randint]\n",
        "print(f\"Picture number {randint} with label: {tar}\")\n",
        "pic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99jkSa_KmrDH"
      },
      "source": [
        "# Task 1: Transform the data (10 pt)\n",
        "\n",
        " Your task is to train a classifier to classify the different land usage types in the dataset. We want to select only the 50 most frequent people in the dataset, all the other people should be mapped to a common class.\n",
        "- Implement the class `rotate` that maps pictures to flipped pictures by 90, 180, 270 or 360°. The class should return an error if you try to rotate the picture by other degrees.\n",
        "- Plot a histogram with the frequencies of each class. Make sure to insert both name and label in the histogram (e.g. `AnnualCrop:0`).\n",
        "- We create a class `RotateEuroSAT` that takes as input the original dataset and returns a new dataset which contains randomly rotated pictures and whose label proportion can be customized.\n",
        "Implement the class method `_create_rotated_dataset` that returns this pictures using the previously implemented `rotate`.\n",
        "- `RotateEuroSAT` should also take care of transforming the pictures to tensors and optionally move the tensor to a GPU device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43onRqgGmalG"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset, Dataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def rotate_picture(picture, rotation):\n",
        "  '''#TODO: implemented most frequent n people'''\n",
        "\n",
        "  return picture\n",
        "\n",
        "\n",
        "def plot_histogram(data):\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(10, 6))\n",
        "  '''#TODO: here your code'''\n",
        "  return fig, ax\n",
        "\n",
        "\n",
        "new_pic = rotate_picture(pic, 90) # Example of rotating a picture by 90 degrees\n",
        "same_pic = rotate_picture(pic, 360) # Example of rotating a picture by 360 degrees (should return the same picture)\n",
        "fig, ax = plot_histogram(data)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSU9ab7ztKRz"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
        "\n",
        "axes[0].imshow(pic)\n",
        "axes[0].set_title(\"Original picture\")\n",
        "axes[1].imshow(new_pic)\n",
        "axes[1].set_title(\"Rotated by 90°\")\n",
        "axes[2].imshow(same_pic)\n",
        "axes[2].set_title(\"Rotated by 360°\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD-Ij7cAt_wu"
      },
      "outputs": [],
      "source": [
        "class RotateEuroSAT(Dataset):\n",
        "    def __init__(self,\n",
        "                 original_data:Dataset,\n",
        "                 length:int,\n",
        "                 shares:list,\n",
        "                 device=None,\n",
        "                 seed=42):\n",
        "\n",
        "        self.original_data = original_data\n",
        "        self.length = length\n",
        "        assert sum(shares)  == 1, \"Shares must sum to 1\"\n",
        "        assert len(shares) == len(original_data.classes), \"Shares must match number of classes\"\n",
        "        self.shares = shares\n",
        "        self.seed = seed\n",
        "        self.device = device\n",
        "        self.dataset = self._create_rotated_dataset()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        picture, label = self.dataset[idx]\n",
        "        return picture, label\n",
        "\n",
        "    def _create_rotated_dataset(self):\n",
        "        \"\"\"#TODO: implement solution\"\"\"\n",
        "        return dataset\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqSWL4YytKRz"
      },
      "outputs": [],
      "source": [
        "rotated_data = RotateEuroSAT(data,\n",
        "                             length=10**4,\n",
        "                             shares=[1 / len(data.classes) for _ in data.classes],\n",
        "                             seed=42)\n",
        "\n",
        "train_data, test_data = random_split(rotated_data, [0.8, 0.2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuDwG0K5hN8K"
      },
      "source": [
        "## Task 2: Implement a max pooling class and a CNN model(15 pt)\n",
        "Implement a classification model to predict the label of the faces in the dataset. You are free to experiment with the network architecture. However your model **must** contain:\n",
        "- At least one max pooling layer, implemented with `MyMaxPool`,\n",
        "- Convolutional, linear, and pooling layers only,\n",
        "- At least 3 convolutional layers, with at least two different kernel sizes,\n",
        "- A final output layer that is customizable to the number of classes that we want to predict.\n",
        "\n",
        "#### Briefly explain why you chose the particular architecture you implemented (around 2-3 sentences).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVHQhPndvqKu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyMaxPool(nn.Sequential):\n",
        "\n",
        "  def __init__(self,\n",
        "               kernel_size,\n",
        "               stride=1,\n",
        "               padding=0):\n",
        "\n",
        "    super().__init__()\n",
        "    '''#TODO: construction your model'''\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''#TODO: forward step'''\n",
        "\n",
        "\n",
        "class MyCNNModel(nn.Sequential):\n",
        "\n",
        "  def __init__(self,\n",
        "               n_classes):\n",
        "\n",
        "    super().__init__()\n",
        "    '''#TODO: construction your model'''\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''#TODO: forward step'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOVl0a2kHupx"
      },
      "outputs": [],
      "source": [
        "'''#TODO: print one iteration of your model to test its correctness'''\n",
        "\n",
        "my_model = MyCNNModel(n_classes=3)\n",
        "X, y = train_data[0]\n",
        "my_model(X[None, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No6lasumGTkQ"
      },
      "source": [
        "## Training\n",
        "\n",
        "We define a `Trainer` function to train our model that returns avg loss and avg accuracy per epoch. We set the configuration of the trainer is set in the `cfg` dictionary. Use the trainer to train your model and make sure to print and plot avg loss and accuracy using the in-built commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsUHs5doTPD0"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime as dt\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cfg = {\n",
        "    'batch_size': 64,\n",
        "    'criterion': 'CrossEntropyLoss', #change to 'nn.NLLLoss' if you are applying a softmax in the last layer of your model\n",
        "    'epochs': 1,\n",
        "    'learning_rate': 0.001,\n",
        "    'optimizer':'Adam',\n",
        "    'seed':42,\n",
        "\n",
        "}\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, model, cfg):\n",
        "        self.model = model\n",
        "        self.cfg = cfg\n",
        "\n",
        "        for key, val in cfg.items():\n",
        "            setattr(self, key, val)\n",
        "\n",
        "        self.optimizer = getattr(optim, self.optimizer)(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = getattr(nn, self.criterion)()\n",
        "\n",
        "\n",
        "    def iter_step(self, X, Y):\n",
        "        Y_pred = self.model(X)\n",
        "        loss = self.criterion(Y_pred, Y)\n",
        "        acc = (Y_pred.argmax(dim=-1) == Y).to(torch.float).mean()\n",
        "        return loss, acc\n",
        "\n",
        "    def train(self, dataset):\n",
        "        train_dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, generator=torch.manual_seed(self.seed))\n",
        "        avg_loss, avg_acc = [], []\n",
        "        tot_loss, tot_acc = 0, 0\n",
        "        for epoch in range(self.epochs):\n",
        "            iterdata = iter(train_dataloader)\n",
        "            train_size = len(iterdata)\n",
        "            pbar = tqdm(iterable=range(train_size))\n",
        "\n",
        "            for i in pbar:\n",
        "                batch = next(iterdata)\n",
        "                X_batch, Y_batch = batch #this is needed for compatibility with pbar\n",
        "                self.model.train()\n",
        "                self.optimizer.zero_grad()\n",
        "                loss, acc = self.iter_step(X_batch, Y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                tot_loss += loss.item()\n",
        "                tot_acc += acc.item()\n",
        "                avg_loss.append(tot_loss / max(1, len(avg_loss)))\n",
        "                avg_acc.append(tot_acc / max(1, len(avg_acc)))\n",
        "                desc = f'Epoch:{epoch} - Avg loss:{avg_loss[-1]:.5f} - Avg acc:{avg_acc[-1]:.5f}'\n",
        "                pbar.set_description(desc)\n",
        "\n",
        "        return avg_loss, avg_acc\n",
        "\n",
        "    def test(self, dataset):\n",
        "        avg_test_loss, avg_test_acc = [], []\n",
        "        test_loss, test_acc = 0, 0\n",
        "        self.model.eval()\n",
        "        test_dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, generator=torch.manual_seed(self.seed))\n",
        "\n",
        "        for X_batch, Y_batch in iter(test_dataloader):\n",
        "            loss, acc = self.iter_step(X_batch, Y_batch)\n",
        "            test_loss += loss.item()\n",
        "            test_acc += acc\n",
        "            avg_test_loss.append(test_loss / max(1, len(avg_test_loss)))\n",
        "            avg_test_acc.append(test_acc / max(1, len(avg_test_acc)))\n",
        "\n",
        "        return avg_test_loss, avg_test_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iDGmuiGksqP"
      },
      "outputs": [],
      "source": [
        "'''#TODO: train your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "my_trainer = Trainer(my_model, cfg)\n",
        "train_loss, train_acc = my_trainer.train(train_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(train_loss)), train_loss)\n",
        "ax1.plot(range(len(train_acc)), train_acc)\n",
        "ax0.set_title('Training loss')\n",
        "ax1.set_title('Training accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDfgU18pllpT"
      },
      "outputs": [],
      "source": [
        "'''#TODO: test your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "test_loss, test_acc = my_trainer.test(test_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(test_loss)), test_loss)\n",
        "ax1.plot(range(len(test_acc)), test_acc)\n",
        "ax0.set_title('Test loss')\n",
        "ax1.set_title('Test accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AvPUd76zVOk"
      },
      "source": [
        "## Task 3: Tune your training hyperparameters (optional, 10 pt)\n",
        "\n",
        "Implement a method <code>grid_search</code>, which looks for the best possible learning rates and training batch sizes for your model <code>MyCNNModel</code> and returns the best possible model, the corresponding training configuration, and the final training avg losses and accuracies (as numbers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJtGS3EB4NFy"
      },
      "outputs": [],
      "source": [
        "def grid_search(train_dataset, cfg, learning_rates=[10**-1, 10**-2, 10**-3], batch_sizes=[2**5, 2**6, 2**7]):\n",
        "    '''#TODO: here your code '''\n",
        "    return best_model, best_cfg, best_avg_loss, best_avg_acc\n",
        "\n",
        "\n",
        "best_model, best_cfg, best_avg_loss, best_avg_acc = grid_search(train_data, cfg, learning_rates=[10**-1, 10**-2, 10**-3], batch_sizes=[2**5, 2**6, 2**7])\n",
        "print(f\"Best model achieves {best_avg_loss:.2f} loss and {best_avg_acc:.1%} accuracy\").\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLLCQpv14Gsx"
      },
      "source": [
        "## Task 3: Load and fine-tune a pre-trained model (10 pt)\n",
        "\n",
        "<ul>\n",
        "  <li>Load and train a pre-trained model for classification problems, such as those made available in <a href=\"https://huggingface.co/docs/timm\">Hugging Face's timm library</a>. </li>\n",
        "  <li> Make sure to modify the output layer to be compatible with the number of classes. </li>\n",
        "  <li>Print a summary of your results.</li>\n",
        "  <li>Briefly explain why you chose the particular architecture you did (around 2-3 sentences).</li>\n",
        "  </ul>\n",
        "  \n",
        "<b>Note</b>: in case you run into computing-related (e.g. memory) issues, consider choosing another model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na1giLKlT0M3"
      },
      "outputs": [],
      "source": [
        "'''#TODO: import and fine-tune a pretrained model'''\n",
        "loaded_model = None #here your loaded model\n",
        "loaded_trainer = Trainer(loaded_model, cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXjFg5gNl1iO"
      },
      "outputs": [],
      "source": [
        "'''#TODO: train your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "train_loss, train_acc = loaded_trainer.train(train_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(train_loss)), train_loss)\n",
        "ax1.plot(range(len(train_acc)), train_acc)\n",
        "ax0.set_title('Training loss')\n",
        "ax1.set_title('Training accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjKQ8pVql1iO"
      },
      "outputs": [],
      "source": [
        "'''#TODO: test your model, plot accuracy and loss by iteration (one iteration=one batch)'''\n",
        "test_loss, test_acc = loaded_trainer.test(test_data)\n",
        "fig, (ax0, ax1) = plt.subplots(1,2)\n",
        "ax0.plot(range(len(test_loss)), test_loss)\n",
        "ax1.plot(range(len(test_acc)), test_acc)\n",
        "ax0.set_title('Test loss')\n",
        "ax1.set_title('Test accuracy')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhkmytKNU_Z2"
      },
      "source": [
        "<a name=\"results-and-discussion\"></a>\n",
        "# Task  4: Results and discussion (5pt)\n",
        "\n",
        "Report the final metrics and make a few comments on the overall performance for the networks you implemented (3-4 lines).\n",
        "\n",
        "| Test metric         | your model | pre-trained model | your tuned model (optional) |\n",
        "|---------------------|--------------------|-------------------|-----------------------|\n",
        "| Accuracy (train)           |              |             |                |                     \n",
        "| Loss (train)               |               |             |                |    \n",
        "| Accuracy (test)           |              |             |                |                     \n",
        "| Loss (test)               |               |             |                |              \n",
        "             \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}